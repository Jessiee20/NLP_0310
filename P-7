import nltk
from nltk.tokenize import word_tokenize
from nltk import pos_tag
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger_eng')
sentence = "Natural language processing is interesting"
tokens = word_tokenize(sentence)
tags = pos_tag(tokens)
print("Tokens:", tokens)
print("POS Tags:")
for word, tag in tags:
    print(word, "â†’", tag)
